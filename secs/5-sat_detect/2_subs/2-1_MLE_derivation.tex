% \section{Maximum Likelihood Estimate Derivation \label{sec::mle_derivation}}
Consider,
\begin{align}
        \varepsilon_\eta(k) &= \eta_{sat}(k) - \eta\lr{k}  \quad
        \implies& \varepsilon_\eta(k) = \lr{\phi_{sat}^T \theta_{sat} - \eta \lr{k}} \label{eqn::eta_regression}
\end{align}
based on the measurement sensors. Assuming $\varepsilon_\eta$ follows half-normal distribution \cite{byers2014half} with scale-parameter, $\sigma$,
\begin{align}
        \varepsilon_\eta &\backsim \text{Half-Normal}(\sigma);\quad
        p(\varepsilon_\eta;\sigma) = \begin{cases} \frac{\sqrt{2}}{\sigma \sqrt{\pi}} e^{- \frac{\varepsilon_\eta^2}{2 \sigma^2}} & \varepsilon_\eta \geq  0\\
                                                        0 & \varepsilon_{\eta} < 0
                                        \end{cases}
                                        \label{eqn::exp_pdf}
\end{align}
The distribution of the error is validated using the data from test-cell experiments. The error is observed to be
non-negative and have a long tail, which is consistent with the assumption of a half-normal distribution for the error
(Figure~\ref{fig::error_dist}).
\begin{figure}[!ht]
        \centering
        \includegraphics[width=\figWidth]{./figs/5-sat_detect/2_param_dist/eta_dist.png}
        \caption{Distribution of $\varepsilon_\eta = \eta_{sat}(k) - \eta(k)$}
        \label{fig::error_dist}
\end{figure}
% ====
We have the likelihood and log-likelihood functions given the data and parameter estimate $\theta_{sat}$ and $\sigma$:
\begin{align}
        l\lr{\theta_{sat}}&=p(\pmb \varepsilon_{\eta};\theta_{sat}, \sigma) = \prod_{k=1}^N  \frac{\sqrt{2}}{\sigma \sqrt{\pi}} e^{- \frac{\varepsilon_\eta^2}{2 \sigma^2}} \quad \varepsilon_\eta(k) \geq  0
        \label{eqn::likelihood}\\
        L\lr{\theta_{sat}}&=\ln \lr{l(\theta_{sat})} = \frac{N}{2} \ln \frac{2}{\sigma^2 \pi} - \frac{1}{2 \sigma^2} {\sum_{k=1}^N \varepsilon_\eta^2}
                \quad \varepsilon_\eta(k) \geq  0
        \label{eqn::log_likelihood}
\end{align}
where $N$ is the total sample size. The maximum likelihood estimate for $\theta_{sat}$ would be:
\begin{align}
        \hat \theta_{sat}
        &= \argmax_{\theta_{sat}} \lrf{ \frac{N}{2} \ln \frac{2}{\sigma^2 \pi} - \frac{1}{2 \sigma^2} {\sum_{k=1}^N \varepsilon_\eta^2} } \quad \varepsilon_\eta(k) \geq  0 \notag\\
        &= \argmin_{\theta_{sat}} \lr{\sum_{k=1}^N \varepsilon_\eta^2} \quad \varepsilon_\eta(k) \geq  0 \notag\\
        &= \argmin_{\theta_{sat}} \lr{\sum_{k=1}^N \lr{\phi_{sat}(k)^T \theta_{sat} - \eta(k)}^2} \notag\\
        &\quad  s.t \quad \phi_{sat}(k)^T \theta_{sat} \geq \eta(k) \quad \forall \: k \in {1,2, \hdots, N}
        \label{eqn::quad_prog}
\end{align}
%%
% Write the link between argmax to argmin.
%%
The quadratic program with a positivity constraint can be relaxed to a linear program as follows. By norm equivalence,
the $l_2-$norm in (\ref{eqn::quad_prog}) is replaced with the $l_1$-norm, and the nonnegativity constraint renders the
absolute value redundant, yielding the linear programming formulation in (\ref{eqn::lin_prog_final}).
\begin{align}
        \hat \theta_{sat}
        &= \argmin_{\theta_{sat}} \lr{\sum_{k=1}^N \lr{\phi_{sat}(k)^T \theta_{sat}}} \notag\\
        &\quad  s.t \quad \phi_{sat}(k)^T \theta_{sat} \geq \eta(k) \quad \forall \: k \in {1,2, \hdots, N}
        \label{eqn::lin_prog_final}
\end{align}

% =================================================================================================================

Using asymptotic properties of MLE (Theorem-7.3 in \cite{kay1993estimation}), with significantly large data length
$(N)$, the parameter estimate $\hat \theta_{sat}$ asymptotically follows a normal distribution under some regularity
conditions on the PDF $p(\pmb \varepsilon_n; \theta_{sat})$.
\begin{align}
        \hat \theta_{sat} \sim \mathcal{N} \lr{\theta_{sat},  I^{-1}(\theta_{sat})}
        \label{eqn::theta_dist}
\end{align}
where $I(\theta_{sat})$ is the Fisher information matrix evaluated at the true value of the parameter $(\theta_{sat})$.
The regularity conditions require the existence of derivatives of the log-likelihood function and the Fisher information
being non-zero. Using the log-likelihood function, $L(\theta_{sat})$, for half-normal distribution
(\ref{eqn::log_likelihood}), we have,
\begin{align}
        \lrb{I(\theta_{sat})}_{ij} &= -E \lrb{\frac{\partial^2 L\lr{\theta_{sat}}}{\partial \theta_j
        \partial \theta_i}} = \frac{1}{\sigma^2} {\sum_{k=1}^{N} \frac{\partial \varepsilon_\eta(k)}{\partial \theta_i}\frac{\partial \varepsilon_\eta(k)}{\partial \theta_j}} \notag \\
        I(\theta_{sat}) &= \frac{1}{\sigma^2} \lrb{\Phi_{sat}^T \Phi_{sat}}
        \label{eqn::fisher_information}
\end{align}

The variance in the $\eta_{sat}$ prediction for the given time-step is obtained by propagating the
uncertainty of parameter estimates (\ref{eqn::theta_dist}). Using, (\ref{eqn::regression}), we have,
\begin{align}
        \Var\lrb{\eta_{sat}(k)} &= \phi_{sat}(k)^T I^{-1}(\theta_{sat}) \phi_{sat}(k)
\end{align}
This variance is used to find the uncertainty bands for the $\alpha_{sat}$ prediction in Figure~\ref{fig::alpha_sat_0}.
